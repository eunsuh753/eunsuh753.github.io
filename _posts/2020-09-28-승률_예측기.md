```python
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import re
import warnings
warnings.filterwarnings(action='ignore')
```


```python
import os
os.chdir("C:\\Users\\swan3\\Desktop\\2020 빅콘 야구\\concat_data")
```


```python
team_pitcher = pd.read_csv('팀투수_total.csv', engine='python',index_col=0) # 팀투수 데이터
team_batter = pd.read_csv('팀타자_total.csv', engine='python',index_col=0) # 팀타자 데이터
```


```python
team_batter.shape
```




    (6400, 29)




```python
team_pitcher.shape
```




    (6400, 35)



# 팀투수 데이터 전처리


```python
team_pitcher
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }
    
    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>G_ID</th>
      <th>GDAY_DS</th>
      <th>T_ID</th>
      <th>VS_T_ID</th>
      <th>HEADER_NO</th>
      <th>TB_SC</th>
      <th>CG_CK</th>
      <th>WLS</th>
      <th>HOLD</th>
      <th>INN2</th>
      <th>...</th>
      <th>P_WHIP_RT</th>
      <th>P2_WHIP_RT</th>
      <th>CB_WHIP_RT</th>
      <th>Year</th>
      <th>ERA</th>
      <th>OBP</th>
      <th>AWHIP</th>
      <th>AVG</th>
      <th>FIP</th>
      <th>RA</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>20160401HHLG0</td>
      <td>20160401</td>
      <td>LG</td>
      <td>HH</td>
      <td>0</td>
      <td>B</td>
      <td>0</td>
      <td>W</td>
      <td>0</td>
      <td>36</td>
      <td>...</td>
      <td>0.642857</td>
      <td>1.285714</td>
      <td>2.400000</td>
      <td>2016</td>
      <td>NaN</td>
      <td>0.326531</td>
      <td>1.333333</td>
      <td>0.282609</td>
      <td>2.283333</td>
      <td>3.000000</td>
    </tr>
    <tr>
      <th>1</th>
      <td>20160401HHLG0</td>
      <td>20160401</td>
      <td>HH</td>
      <td>LG</td>
      <td>0</td>
      <td>T</td>
      <td>0</td>
      <td>L</td>
      <td>0</td>
      <td>34</td>
      <td>...</td>
      <td>1.500000</td>
      <td>1.000000</td>
      <td>0.750000</td>
      <td>2016</td>
      <td>NaN</td>
      <td>0.282609</td>
      <td>1.147059</td>
      <td>0.214286</td>
      <td>3.464706</td>
      <td>3.970588</td>
    </tr>
    <tr>
      <th>2</th>
      <td>20160401HTNC0</td>
      <td>20160401</td>
      <td>NC</td>
      <td>HT</td>
      <td>0</td>
      <td>B</td>
      <td>0</td>
      <td>W</td>
      <td>0</td>
      <td>27</td>
      <td>...</td>
      <td>1.333333</td>
      <td>1.038462</td>
      <td>2.142857</td>
      <td>2016</td>
      <td>NaN</td>
      <td>0.315789</td>
      <td>1.222222</td>
      <td>0.235294</td>
      <td>3.755556</td>
      <td>4.000000</td>
    </tr>
    <tr>
      <th>3</th>
      <td>20160401HTNC0</td>
      <td>20160401</td>
      <td>HT</td>
      <td>NC</td>
      <td>0</td>
      <td>T</td>
      <td>0</td>
      <td>L</td>
      <td>0</td>
      <td>24</td>
      <td>...</td>
      <td>0.500000</td>
      <td>1.695652</td>
      <td>1.875000</td>
      <td>2016</td>
      <td>NaN</td>
      <td>0.400000</td>
      <td>1.750000</td>
      <td>0.300000</td>
      <td>6.075000</td>
      <td>5.625000</td>
    </tr>
    <tr>
      <th>4</th>
      <td>20160401KTSK0</td>
      <td>20160401</td>
      <td>SK</td>
      <td>KT</td>
      <td>0</td>
      <td>B</td>
      <td>0</td>
      <td>L</td>
      <td>0</td>
      <td>27</td>
      <td>...</td>
      <td>1.000000</td>
      <td>2.357143</td>
      <td>2.250000</td>
      <td>2016</td>
      <td>NaN</td>
      <td>0.380952</td>
      <td>1.666667</td>
      <td>0.305556</td>
      <td>6.200000</td>
      <td>8.000000</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>6395</th>
      <td>20200719LTSS0</td>
      <td>20200719</td>
      <td>LT</td>
      <td>SS</td>
      <td>0</td>
      <td>T</td>
      <td>0</td>
      <td>W</td>
      <td>2</td>
      <td>27</td>
      <td>...</td>
      <td>0.600000</td>
      <td>1.111111</td>
      <td>1.500000</td>
      <td>2020</td>
      <td>NaN</td>
      <td>0.294118</td>
      <td>1.111111</td>
      <td>0.225806</td>
      <td>3.644444</td>
      <td>1.000000</td>
    </tr>
    <tr>
      <th>6396</th>
      <td>20200719OBHT0</td>
      <td>20200719</td>
      <td>HT</td>
      <td>OB</td>
      <td>0</td>
      <td>B</td>
      <td>0</td>
      <td>L</td>
      <td>0</td>
      <td>27</td>
      <td>...</td>
      <td>2.142857</td>
      <td>1.800000</td>
      <td>0.750000</td>
      <td>2020</td>
      <td>NaN</td>
      <td>0.365854</td>
      <td>1.555556</td>
      <td>0.297297</td>
      <td>4.755556</td>
      <td>8.000000</td>
    </tr>
    <tr>
      <th>6397</th>
      <td>20200719OBHT0</td>
      <td>20200719</td>
      <td>OB</td>
      <td>HT</td>
      <td>0</td>
      <td>T</td>
      <td>0</td>
      <td>W</td>
      <td>1</td>
      <td>27</td>
      <td>...</td>
      <td>3.000000</td>
      <td>1.000000</td>
      <td>1.875000</td>
      <td>2020</td>
      <td>NaN</td>
      <td>0.368421</td>
      <td>1.555556</td>
      <td>0.250000</td>
      <td>4.088889</td>
      <td>4.000000</td>
    </tr>
    <tr>
      <th>6398</th>
      <td>20200719WOSK0</td>
      <td>20200719</td>
      <td>SK</td>
      <td>WO</td>
      <td>0</td>
      <td>B</td>
      <td>0</td>
      <td>W</td>
      <td>0</td>
      <td>27</td>
      <td>...</td>
      <td>1.500000</td>
      <td>1.105263</td>
      <td>2.142857</td>
      <td>2020</td>
      <td>NaN</td>
      <td>0.297297</td>
      <td>1.111111</td>
      <td>0.212121</td>
      <td>5.088889</td>
      <td>3.000000</td>
    </tr>
    <tr>
      <th>6399</th>
      <td>20200719WOSK0</td>
      <td>20200719</td>
      <td>WO</td>
      <td>SK</td>
      <td>0</td>
      <td>T</td>
      <td>0</td>
      <td>L</td>
      <td>2</td>
      <td>24</td>
      <td>...</td>
      <td>1.800000</td>
      <td>1.312500</td>
      <td>1.333333</td>
      <td>2020</td>
      <td>NaN</td>
      <td>0.351351</td>
      <td>1.625000</td>
      <td>0.200000</td>
      <td>3.325000</td>
      <td>4.500000</td>
    </tr>
  </tbody>
</table>
<p>6400 rows × 41 columns</p>
</div>




```python
# 평균자책점 ERA (자책점 * 9 / 이닝수)
team_pitcher['ERA'] = team_pitcher['ER']*27/team_pitcher['INN2']
# 피출루율 OBP 계산 
# (HIT+BB+HP)/(AB+BB+HP+SF)
team_pitcher['bm'] = team_pitcher['HIT']+team_pitcher['BB']+team_pitcher['HP']
team_pitcher['bj'] = team_pitcher['AB']+team_pitcher['BB']+team_pitcher['HP']+team_pitcher['SF']

team_pitcher['OBP']=team_pitcher['bm']/team_pitcher['bj']
team_pitcher.drop('bm', axis=1, inplace= True)
team_pitcher.drop('bj', axis=1, inplace= True)

# AWhIP (수정WHIP) : (BB+IB+HIT)*3/INN2
team_pitcher['AWHIP'] = (team_pitcher['BB']+team_pitcher['IB']+team_pitcher['HIT'])*3/team_pitcher['INN2']

# 피안타율(AVG) : 안타수/타수 (HIT/AB)
team_pitcher['AVG'] = team_pitcher['HIT']/team_pitcher['AB']

# FIP : (13*피홈런+3*(볼넷-고의사구+몸맞공)-2*탈삼진)/이닝+FIP상수 
# FIP상수는 3.2근처의 값
team_pitcher['FIP'] = (13*team_pitcher['HR']+3*(team_pitcher['BB']-team_pitcher['IB']+team_pitcher['HP'])-2*team_pitcher['KK'])*3/team_pitcher['INN2']+3.2

# RA (9이닝당 평균실점 (Run Allowed Per 9 Innings Pitched))
team_pitcher['RA'] = team_pitcher['R']*27 / team_pitcher['INN2']
```


```python
team_pitcher['ERA']
```




    0       3.000000
    1       3.176471
    2       4.000000
    3       5.625000
    4       8.000000
              ...   
    6395    1.000000
    6396    8.000000
    6397    4.000000
    6398    3.000000
    6399    4.500000
    Name: ERA, Length: 6400, dtype: float64




```python
team_pitcher.columns
```




    Index(['G_ID', 'GDAY_DS', 'T_ID', 'VS_T_ID', 'HEADER_NO', 'TB_SC', 'CG_CK',
           'WLS', 'HOLD', 'INN2', 'BF', 'PA', 'AB', 'HIT', 'H2', 'H3', 'HR', 'SB',
           'CS', 'SH', 'SF', 'BB', 'IB', 'HP', 'KK', 'GD', 'WP', 'BK', 'ERR', 'R',
           'ER', 'P_WHIP_RT', 'P2_WHIP_RT', 'CB_WHIP_RT', 'Year', 'ERA', 'OBP',
           'AWHIP', 'AVG', 'FIP', 'RA'],
          dtype='object')




```python
# 실점과 단일 수비지표 사이의 상관계수
team_pitcher.corr()['R'].sort_values(ascending = False)
# AWHIP (0.826579) , HIT (0.791998) , OBP (0.769433) , AVG  (0.764717), PA (0.701546) 순으로 상관관계가 높음.
```




    R             1.000000
    RA            0.989944
    ER            0.964062
    ERA           0.957248
    AWHIP         0.826579
    HIT           0.791998
    OBP           0.769433
    AVG           0.764717
    PA            0.701546
    FIP           0.640016
    AB            0.598199
    P_WHIP_RT     0.571641
    BF            0.542360
    HR            0.540718
    P2_WHIP_RT    0.495532
    CB_WHIP_RT    0.489390
    H2            0.479295
    BB            0.358253
    SF            0.273492
    HP            0.204066
    H3            0.200769
    WP            0.192467
    SB            0.125871
    SH            0.080161
    ERR           0.076773
    IB            0.069433
    BK            0.034348
    HEADER_NO    -0.000758
    CS           -0.032512
    GD           -0.053679
    GDAY_DS      -0.074378
    Year         -0.074677
    CG_CK        -0.130326
    KK           -0.131813
    INN2         -0.169750
    HOLD         -0.207956
    Name: R, dtype: float64



# 팀타자 데이터 전처리


```python
team_batter.columns
```




    Index(['G_ID', 'GDAY_DS', 'T_ID', 'VS_T_ID', 'HEADER_NO', 'TB_SC', 'PA', 'AB',
           'RBI', 'RUN', 'HIT', 'H2', 'H3', 'HR', 'SB', 'CS', 'SH', 'SF', 'BB',
           'IB', 'HP', 'KK', 'GD', 'ERR', 'LOB', 'P_HRA_RT', 'P_AB_CN', 'P_HIT_CN',
           'Year'],
          dtype='object')




```python
df2 = team_batter.copy() 
df2['H1'] = df2['HIT'] - df2['H2'] - df2['H3'] - df2['HR']
stats = ['PA', 'AB','RBI', 'RUN', 'HIT', 'H1', 'H2', 'H3', 'HR', 'SB', 'CS', 'SH', 'SF', 'BB','IB', 'HP', 'KK', 'GD', 'ERR']
stats_cum = [i + '_누적' for i in stats]
```


```python
#연도별로 달라질 때마다 누적합 초기화
from tqdm import tqdm

diffIndex=[0]
for i in tqdm(range(0, len(df2)-1)):
    if (df2['Year'][i] != df2['Year'][i+1]):
        diffIndex.append(i+1)

def cum_sum(x):
    s = x.cumsum()
    return s
```

    100%|███████████████████████████████████████████████████████████████████████████| 6399/6399 [00:00<00:00, 37429.71it/s]



```python
for k in tqdm(range(len(stats))):
    df2[stats_cum[k]]=0
    for i in range(len(diffIndex)):
        if i == len(diffIndex)-1 : 
            df2[stats_cum[k]][diffIndex[i]:] = cum_sum(df2[stats[k]][diffIndex[i]:])
        else:
            df2[stats_cum[k]][diffIndex[i]:diffIndex[i+1]] = cum_sum(df2[stats[k]][diffIndex[i]:diffIndex[i+1]])
```

    100%|█████████████████████████████████████████████████████████████████████████████████| 19/19 [00:00<00:00, 119.98it/s]



```python
df2['AVG'] = df2['HIT']/df2['AB']
```


```python
##연도별 누적 세이버메트릭스 지표
#타율 

df2['AVG_누적'] = df2['HIT_누적']/df2['AB_누적']

# 출루율
df2['OBP_누적'] = (df2['HIT_누적']+df2['BB_누적']+df2['HP_누적'])/(df2['AB_누적']+df2['BB_누적']+df2['HP_누적']+df2['SF_누적'])

# 장타율 (1루타 = 안타 - 2루타 - 3루타 - 홈런)
df2['SLG_누적'] = (df2['H1_누적'] + df2['H2_누적']*2 + df2['H3_누적']*3 + df2['HR_누적']*4) / df2['AB_누적']

# OPS => 득점에 많이 공헌 
df2['OPS_누적'] = df2['OBP_누적']+df2['SLG_누적']

# 순장타율
df2['ISO_누적'] = df2['SLG_누적'] - df2['AVG_누적']

#가중 출루율
df2['wOBA_누적'] = (0.72*(df2['BB_누적']-df2['IB_누적'])+0.75*df2['HP_누적']+0.90*df2['H1_누적']+
0.92*df2['ERR_누적']+1.24*df2['H2_누적']+1.56*df2['H3_누적']+1.95*df2['HR_누적']) / (df2['PA_누적']-df2['IB_누적'])

df2['XR_누적'] = 0.5*df2['H1_누적']+0.72*df2['H2_누적']+1.04*df2['H3_누적']
+1.44*df2['HR_누적']+0.34*(df2['BB_누적']-df2['IB_누적']+df2['HP_누적'])+0.25*df2['IB_누적']
+0.18*df2['SB_누적']-0.32*df2['CS_누적']-0.09*(df2['AB_누적']-df2['HIT_누적']-df2['KK_누적'])
-0.098*df2['KK_누적']-0.37*df2['GD_누적']+0.37*df2['SF_누적']+0.04*df2['SH_누적']

df2['XR27_누적'] = (27*df2['XR_누적'])/(df2['AB_누적']-df2['HIT_누적']+df2['SF_누적']+df2['SH_누적']+df2['CS_누적']+df2['GD_누적'])
```


```python
team_batter = df2.copy()
```

## 팀투수, 팀타자 데이터 합치기


```python
team_pitcher.columns
```




    Index(['G_ID', 'GDAY_DS', 'T_ID', 'VS_T_ID', 'HEADER_NO', 'TB_SC', 'CG_CK',
           'WLS', 'HOLD', 'INN2', 'BF', 'PA', 'AB', 'HIT', 'H2', 'H3', 'HR', 'SB',
           'CS', 'SH', 'SF', 'BB', 'IB', 'HP', 'KK', 'GD', 'WP', 'BK', 'ERR', 'R',
           'ER', 'P_WHIP_RT', 'P2_WHIP_RT', 'CB_WHIP_RT', 'Year', 'ERA', 'OBP',
           'AWHIP', 'AVG', 'FIP', 'RA'],
          dtype='object')




```python
team_batter.columns
```




    Index(['G_ID', 'GDAY_DS', 'T_ID', 'VS_T_ID', 'HEADER_NO', 'TB_SC', 'PA', 'AB',
           'RBI', 'RUN', 'HIT', 'H2', 'H3', 'HR', 'SB', 'CS', 'SH', 'SF', 'BB',
           'IB', 'HP', 'KK', 'GD', 'ERR', 'LOB', 'P_HRA_RT', 'P_AB_CN', 'P_HIT_CN',
           'Year', 'H1', 'PA_누적', 'AB_누적', 'RBI_누적', 'RUN_누적', 'HIT_누적', 'H1_누적',
           'H2_누적', 'H3_누적', 'HR_누적', 'SB_누적', 'CS_누적', 'SH_누적', 'SF_누적', 'BB_누적',
           'IB_누적', 'HP_누적', 'KK_누적', 'GD_누적', 'ERR_누적', 'AVG_누적', 'OBP_누적',
           'SLG_누적', 'OPS_누적', 'ISO_누적', 'wOBA_누적', 'XR_누적', 'XR27_누적'],
          dtype='object')




```python
team_batter2 = team_batter[['G_ID', 'GDAY_DS', 'T_ID', 'VS_T_ID', 'RUN', 'AVG','AVG_누적', 'OBP_누적',
       'SLG_누적', 'OPS_누적', 'ISO_누적', 'wOBA_누적', 'XR_누적', 'XR27_누적']]
team_pitcher2 = team_pitcher[['TB_SC','WLS','ERA','P_WHIP_RT', 'R', 'P2_WHIP_RT', 'CB_WHIP_RT','AWHIP','FIP', 'RA']]
team_pitcher2.columns = ['TB_SC','WLS','ERA','P_WHIP_RT', 'VS_RUN', 'P2_WHIP_RT', 'CB_WHIP_RT','AWHIP','FIP', 'RA']
```


```python
team_data = pd.concat([team_batter2, team_pitcher2], axis = 1)
```


```python
# 초말 데이터는 (초 : 1, 말 : 0)으로 변환
team_data['TB_SC'].replace({'B':0, 'T':1}, inplace = True)

# 승패예측할 때 무승부 데이터는 뺌 -> 승 : 1, 패 : 0 으로 변환
idx_D = team_data[team_data['WLS']=="D"].index
team_data = team_data.drop(idx_D)
team_data['WLS'].replace({'W':1, 'L':0}, inplace = True)

# GDAY_DS를 날짜 형태로 변환
import datetime
team_data['GDAY_DS'] = pd.to_datetime(team_data['GDAY_DS'], format = '%Y%m%d')
```


```python
team_data.columns
```




    Index(['G_ID', 'GDAY_DS', 'T_ID', 'VS_T_ID', 'RUN', 'AVG', 'AVG_누적', 'OBP_누적',
           'SLG_누적', 'OPS_누적', 'ISO_누적', 'wOBA_누적', 'XR_누적', 'XR27_누적', 'TB_SC',
           'WLS', 'ERA', 'P_WHIP_RT', 'VS_RUN', 'P2_WHIP_RT', 'CB_WHIP_RT',
           'AWHIP', 'FIP', 'RA'],
          dtype='object')




```python
team_data = team_data[['G_ID', 'GDAY_DS', 'T_ID', 'VS_T_ID','TB_SC', 'WLS','ERA','AVG', 'AVG_누적', 'OBP_누적', 'SLG_누적',
       'OPS_누적', 'ISO_누적', 'wOBA_누적', 'XR_누적', 'XR27_누적','P_WHIP_RT', 'P2_WHIP_RT', 'CB_WHIP_RT', 'AWHIP', 'FIP', 'RA']]
```


```python
team_list = team_data['T_ID'].unique().tolist()
team_list
```




    ['LG', 'HH', 'NC', 'HT', 'SK', 'KT', 'WO', 'LT', 'SS', 'OB']




```python
for i in team_list:
    globals()['{}_data'.format(i)] = team_data[team_data['T_ID']== i]
    globals()['{}_data'.format(i)].reset_index(drop = True, inplace= True)
```

#### 1) 직전 경기 승패 여부


```python
from tqdm import tqdm
for i in team_list:
    globals()['{}_data'.format(i)]['WLS_yest'] = 0
    for k in range(len(globals()['{}_data'.format(i)])-1):
        if k == 0:
            globals()['{}_data'.format(i)]['WLS_yest'][k] = np.NAN
        else:
            globals()['{}_data'.format(i)]['WLS_yest'][k] = globals()['{}_data'.format(i)]['WLS'][k+1]
```


```python
# 2015년 정규시즌 마지막 경기 결과 
LG_data['WLS_yest'][0] = 1
HH_data['WLS_yest'][0] = 0
NC_data['WLS_yest'][0] = 0
HT_data['WLS_yest'][0] = 0
SK_data['WLS_yest'][0] = 0
KT_data['WLS_yest'][0] = 0
WO_data['WLS_yest'][0] = 1
LT_data['WLS_yest'][0] = 1
SS_data['WLS_yest'][0] = 1
OB_data['WLS_yest'][0] = 1
```

#### 2) 경기이전 휴식일수 
- 8일 이상이면 8로 처리


```python
def rest_day(x):
    if x >= 8:
        return 8
    else:
        return x
```


```python
for i in team_list:
    globals()['{}_data'.format(i)]['rest_day'] = 0
    for k in range(len(globals()['{}_data'.format(i)])):
        if k==0:
            globals()['{}_data'.format(i)]['rest_day'][k] = 9
        else: 
            globals()['{}_data'.format(i)]['rest_day'][k] = globals()['{}_data'.format(i)]['GDAY_DS'][k] - globals()['{}_data'.format(i)]['GDAY_DS'][k-1]

    globals()['{}_data'.format(i)]['rest_day'] = globals()['{}_data'.format(i)]['rest_day'].astype(str) 
    p = re.compile('\d{1,3}')
    globals()['{}_data'.format(i)]['rest_day'] = globals()['{}_data'.format(i)]['rest_day'].map(lambda x: p.findall(x)[0])
    globals()['{}_data'.format(i)]['rest_day'] = globals()['{}_data'.format(i)]['rest_day'].astype(int) - 1
    globals()['{}_data'.format(i)]['rest_day'] = globals()['{}_data'.format(i)]['rest_day'].apply(lambda x: rest_day(x))
```

#### 상대팀과의 연전수


```python
#상대팀이 달라질 때마다 인덱스 초기화
from tqdm import tqdm
for i in team_list:
    diffIndex=[0]
    for k in range(0, len(globals()['{}_data'.format(i)])-1):
        if (globals()['{}_data'.format(i)]['VS_T_ID'][k] != globals()['{}_data'.format(i)]['VS_T_ID'][k+1]):
            diffIndex.append(k+1)
    
    globals()['{}_data'.format(i)]['vs_conti'] = 0
    
    for q in range(len(diffIndex)-1) : 
        j = diffIndex[q+1]-diffIndex[q]
        globals()['{}_data'.format(i)]['vs_conti'][diffIndex[q]:diffIndex[q+1]] = np.arange(0,j).tolist()

    j = len(globals()['{}_data'.format(i)])- diffIndex[-1]
    globals()['{}_data'.format(i)]['vs_conti'][diffIndex[-1]:] = np.arange(0,j).tolist()
```


```python
total_data = pd.concat([LG_data, HH_data, NC_data, HT_data, SK_data, KT_data, WO_data, LT_data, SS_data, OB_data])
total_data.sort_values(by='G_ID', inplace=True)
```


```python
total_data.columns = ['G_ID', 'GDAY_DS', 'T_ID', 'VS_T_ID', 'TB_SC', 'WLS','ERA', 'AVG', 'AVG_cum',
       'OBP_cum', 'SLG_cum', 'OPS_cum', 'ISO_cum', 'wOBA_cum', 'XR_cum', 'XR27_cum',
       'P_WHIP_RT', 'P2_WHIP_RT', 'CB_WHIP_RT', 'AWHIP', 'FIP', 'RA',
       'WLS_yest', 'rest_day', 'vs_conti']
```

## 이상치 제거


```python
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# 박스플롯 그리기
sns.boxplot(total_data['P2_WHIP_RT'])
plt.show()
```

![output_40_0](https://user-images.githubusercontent.com/62747570/140241952-aef1f71a-c14b-4cb1-87fe-e38d3c54f8dd.png)





```python
df = total_data['P2_WHIP_RT']
Q1 = np.percentile(df,25)
Q3 = np.percentile(df,75)
IQR = Q3 - Q1
outlier_step = 1.5*IQR
lowest = Q1 - outlier_step
highest = Q3 + outlier_step
```


```python
total_data[total_data['P2_WHIP_RT']>=highest]['P2_WHIP_RT'] = highest
```


```python
total_data['P2_WHIP_RT'] = total_data['P2_WHIP_RT'].map(lambda x: highest
                            if x >= highest
                            else x)
```


```python
# 이상치 제거 후 boxplot
sns.boxplot(total_data['P2_WHIP_RT'])
plt.show()
```

![output_44_0](https://user-images.githubusercontent.com/62747570/140241953-e82089d2-8c2d-4c34-af74-2203c69f2ee6.png)





```python
#CB_WHIP_RT : 처리전
sns.boxplot(total_data['CB_WHIP_RT'])
plt.show()
```

![output_45_0](https://user-images.githubusercontent.com/62747570/140241954-c3e5cc99-2b73-4607-a750-3ce765d8a040.png)





```python
df = total_data['CB_WHIP_RT']
Q1 = np.percentile(df,25)
Q3 = np.percentile(df,75)
IQR = Q3 - Q1
outlier_step = 1.5*IQR
lowest = Q1 - outlier_step
highest = Q3 + outlier_step
```


```python
total_data['CB_WHIP_RT'] = total_data['CB_WHIP_RT'].map(lambda x: highest
                            if x >= highest
                            else x)
```


```python
##CB_WHIP_RT : 처리후
sns.boxplot(total_data['CB_WHIP_RT'])
plt.show()
```

![output_48_0](https://user-images.githubusercontent.com/62747570/140241955-51946fdd-dceb-4dc8-a3e7-ae286b9bdf59.png)





```python
total_data.to_csv("승률_데이터.csv", encoding = 'cp949')
```

# 모델링 - Bagging Classifier


```python
total_data = pd.read_csv("승률_데이터.csv", encoding = 'cp949')
```


```python
import warnings
warnings.filterwarnings(action='ignore')

from sklearn.model_selection import train_test_split
```


```python
import numpy as np
from sklearn.preprocessing import LabelEncoder

# 라벨 인코더 생성
encoder = LabelEncoder()

# X_train데이터를 이용 피팅하고 라벨숫자로 변환한다
encoder.fit(total_data['T_ID'])
total_data['T_ID'] = encoder.transform(total_data['T_ID'])

encoder.fit(total_data['VS_T_ID'])
total_data['VS_T_ID'] = encoder.transform(total_data['VS_T_ID'])
```


```python
total_data.columns = ['G_ID', 'GDAY_DS', 'T_ID','VS_T_ID','TB_SC','WLS', 'ERA','AVG', 'AVG_cum','OBP_cum', 'SLG_cum', 'OPS_cum', 'ISO_cum', 'wOBA_cum', 'XR_cum', 'XR27_cum',
       'P_WHIP_RT', 'P2_WHIP_RT', 'CB_WHIP_RT', 'AWHIP', 'FIP', 'RA', 'WLS_yest', 'rest_day', 'vs_conti']
```

### 여러가지 변수를 넣고 빼가면서 최적 모델링 찾음


```python
cols3 = ['T_ID','VS_T_ID','TB_SC','AVG_cum','OPS_cum','P2_WHIP_RT', 'CB_WHIP_RT', 'AWHIP', 'FIP', 'RA',
       'WLS_yest', 'rest_day', 'vs_conti']
X3 = total_data[cols3]
y3 = total_data['WLS']
X_train, X_test, y_train, y_test = train_test_split(X3, y3, test_size=0.33, random_state=42)
```


```python
cols9 = ['T_ID','VS_T_ID','TB_SC','AVG_cum','P2_WHIP_RT', 'CB_WHIP_RT', 'AWHIP',
       'WLS_yest', 'rest_day', 'vs_conti', 'ERA']
X3 = total_data[cols9]
y3 = total_data['WLS']
X_train, X_test, y_train, y_test = train_test_split(X3, y3, test_size=0.33, random_state=42)
```


```python
cols10 = ['T_ID','VS_T_ID','TB_SC','AVG','P2_WHIP_RT', 'CB_WHIP_RT', 'AWHIP',
       'WLS_yest', 'rest_day', 'vs_conti', 'ERA']
X3 = total_data[cols10]
y3 = total_data['WLS']
X_train, X_test, y_train, y_test = train_test_split(X3, y3, test_size=0.2, random_state=42)
```


```python
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score
from sklearn.metrics import f1_score, confusion_matrix, precision_recall_curve, roc_curve
from sklearn.preprocessing import StandardScaler

# 성능 지표 출력 함수
def get_clf_eval(y_test, pred=None, pred_proba=None):
    confusion = confusion_matrix(y_test, pred)
    accuracy = accuracy_score(y_test, pred)
    precision = precision_score(y_test, pred)
    recall = recall_score(y_test, pred)
    f1 = f1_score(y_test, pred)
    
    roc_auc = roc_auc_score(y_test, pred_proba)
    print("오차 행렬")
    print(confusion)
    print("정확도: {0:.4f}, 정밀도: {1:.4f}, 재현율: {2:.4f}, F1: {3:.4f}, AUC: {4:.4f}".format(accuracy, precision, recall, f1, roc_auc))
```


```python
from sklearn.ensemble import BaggingClassifier
from sklearn.tree import DecisionTreeClassifier

bag_clf = BaggingClassifier(DecisionTreeClassifier(), n_estimators=1600, max_samples=850, bootstrap=True, random_state=156)
bag_clf.fit(X_train, y_train)
bag_pred = bag_clf.predict(X_test)
```


```python
# col3 'P2_WHIP_RT', 'CB_WHIP_RT', 'AWHIP'
bag_clf = BaggingClassifier(DecisionTreeClassifier(), n_estimators=1600, max_samples=850, bootstrap=True, random_state=156)
bag_clf.fit(X_train, y_train)
bag_pred = bag_clf.predict(X_test)
pred_proba = bag_clf.predict_proba(X_test)[:, 1] #개별 레이블별 예측확률
get_clf_eval(y_test, bag_pred, pred_proba)
```

    오차 행렬
    [[911 134]
     [162 884]]
    정확도: 0.8584, 정밀도: 0.8684, 재현율: 0.8451, F1: 0.8566, AUC: 0.9289



```python
#col9 FIP 빼고
bag_clf = BaggingClassifier(DecisionTreeClassifier(), n_estimators=1600, max_samples=850, bootstrap=True, random_state=156)
bag_clf.fit(X_train, y_train)
bag_pred = bag_clf.predict(X_test)
pred_proba = bag_clf.predict_proba(X_test)[:, 1] #개별 레이블별 예측확률
get_clf_eval(y_test, bag_pred, pred_proba)
```

    오차 행렬
    [[897 148]
     [166 880]]
    정확도: 0.8498, 정밀도: 0.8560, 재현율: 0.8413, F1: 0.8486, AUC: 0.9272



```python
#col10 AVG_cum -> AVG 
bag_clf = BaggingClassifier(DecisionTreeClassifier(), n_estimators=1600, max_samples=850, bootstrap=True, random_state=156)
bag_clf.fit(X_train, y_train)
bag_pred = bag_clf.predict(X_test)
pred_proba = bag_clf.predict_proba(X_test)[:, 1] #개별 레이블별 예측확률
get_clf_eval(y_test, bag_pred, pred_proba)
```

    오차 행렬
    [[553  83]
     [ 78 553]]
    정확도: 0.8729, 정밀도: 0.8695, 재현율: 0.8764, F1: 0.8729, AUC: 0.9485


## 랜포 
- 변수 중요도 뽑음


```python
from sklearn.ensemble import RandomForestClassifier

#Create a Gaussian Classifier
rf_clf=RandomForestClassifier(n_estimators=400)

#Train the model using the training sets y_pred=clf.predict(X_test)
rf_clf.fit(X_train,y_train)

rf_pred=rf_clf.predict(X_test)
```


```python
pred_proba = rf_clf.predict_proba(X_test)[:, 1] #개별 레이블별 예측확률
get_clf_eval(y_test, rf_pred, pred_proba)
```

    오차 행렬
    [[868 177]
     [193 853]]
    정확도: 0.8231, 정밀도: 0.8282, 재현율: 0.8155, F1: 0.8218, AUC: 0.9069



```python
import pandas as pd
feature_imp = pd.Series(rf_clf.feature_importances_,index=cols10).sort_values(ascending=False)
feature_imp
```




    ERA           0.402191
    WHIP_total    0.245850
    AVG_cum       0.133979
    VS_T_ID       0.064068
    T_ID          0.063483
    vs_conti      0.027785
    rest_day      0.022066
    TB_SC         0.021249
    WLS_yest      0.019328
    dtype: float64



## 임계값 조정 


```python
from sklearn.preprocessing import Binarizer

# 평가지표를 조사하기 위한 새로운 함수 생성
def get_eval_by_threshold(y_test, pred_proba_c1, thresholds):
    #thresholds list 객체 내의 값을 iteration 하면서 평가 수행
    for custom_threshold in thresholds:
        binarizer = Binarizer(threshold=custom_threshold).fit(pred_proba_c1)
        custom_predict = binarizer.transform(pred_proba_c1)
        print('\n임계값: ', custom_threshold)
        get_clf_eval(y_test, custom_predict, pred_proba_c1)
```


```python
# 임계값
thresholds = [0.47, 0.48, 0.49, 0.50, 0.51, 0.52, 0.53, 0.54, 0.55]
pred_proba = bag_clf.predict_proba(X_test)
get_eval_by_threshold(y_test, pred_proba[:,1].reshape(-1, 1), thresholds)
```


    임계값:  0.47
    오차 행렬
    [[882 163]
     [106 940]]
    정확도: 0.8714, 정밀도: 0.8522, 재현율: 0.8987, F1: 0.8748, AUC: 0.9470
    
    임계값:  0.48
    오차 행렬
    [[891 154]
     [111 935]]
    정확도: 0.8733, 정밀도: 0.8586, 재현율: 0.8939, F1: 0.8759, AUC: 0.9470
    
    임계값:  0.49
    오차 행렬
    [[896 149]
     [117 929]]
    정확도: 0.8728, 정밀도: 0.8618, 재현율: 0.8881, F1: 0.8748, AUC: 0.9470
    
    임계값:  0.5
    오차 행렬
    [[905 140]
     [124 922]]
    정확도: 0.8737, 정밀도: 0.8682, 재현율: 0.8815, F1: 0.8748, AUC: 0.9470
    
    임계값:  0.51
    오차 행렬
    [[914 131]
     [130 916]]
    정확도: 0.8752, 정밀도: 0.8749, 재현율: 0.8757, F1: 0.8753, AUC: 0.9470
    
    임계값:  0.52
    오차 행렬
    [[919 126]
     [136 910]]
    정확도: 0.8747, 정밀도: 0.8784, 재현율: 0.8700, F1: 0.8742, AUC: 0.9470
    
    임계값:  0.53
    오차 행렬
    [[923 122]
     [142 904]]
    정확도: 0.8737, 정밀도: 0.8811, 재현율: 0.8642, F1: 0.8726, AUC: 0.9470
    
    임계값:  0.54
    오차 행렬
    [[928 117]
     [149 897]]
    정확도: 0.8728, 정밀도: 0.8846, 재현율: 0.8576, F1: 0.8709, AUC: 0.9470
    
    임계값:  0.55
    오차 행렬
    [[931 114]
     [157 889]]
    정확도: 0.8704, 정밀도: 0.8863, 재현율: 0.8499, F1: 0.8677, AUC: 0.9470


임계값이 0.51일 때 F1 score 최대 


```python
import matplotlib.pyplot as plt
import matplotlib.ticker as ticker
%matplotlib inline

def precision_recall_curve_plot(y_test, pred_proba_c1):
    # threshold ndarray와 이 threshold에 따른 정밀도, 재현율 ndarray 추출
    precisions, recalls, thresholds = precision_recall_curve(y_test, pred_proba_c1)
    
    # x축을 threshold 값, y축을 정밀도, 재현율로 그리기
    plt.figure(figsize=(8,6))
    thresholds_boundary = thresholds.shape[0]
    plt.plot(thresholds, precisions[0: thresholds_boundary], linestyle= '--', label='precision')
    plt.plot(thresholds, recalls[0: thresholds_boundary], label='recall')
    
    # threshold의 값 X축의 scale을 0.1 단위로 변경
    stard, end = plt.xlim()
    plt.xticks(np.round(np.arange(stard, end, 0.1), 2))
    
    # x축, y축 label과 legend, 그리고 grid 설정
    plt.xlabel('Threshold value')
    plt.ylabel('Precision and Recall value')
    plt.legend()
    plt.grid()
    plt.show()
```


```python
precision_recall_curve_plot(y_test, bag_clf.predict_proba(X_test)[:,1])
```

![output_73_0](https://user-images.githubusercontent.com/62747570/140241956-882b0a52-6df8-4f24-9fdf-c7867df40d7b.png)





```python
# 임계값을 0.51로 설정하여 예측 수행
binarizer = Binarizer(threshold=0.51)

# 위에서 구한 predict_proba() 예측확률의 array에서 1에 해당하는 컬럼 값을 대입하여 Binarizer 반환하기
pred_th_051 = binarizer.fit_transform(pred_proba[:, 1].reshape(-1, 1))

get_clf_eval(y_test, pred_th_051, pred_proba[:,1])
```

    오차 행렬
    [[891 154]
     [111 935]]
    정확도: 0.8733, 정밀도: 0.8586, 재현율: 0.8939, F1: 0.8759, AUC: 0.9470


## X_test 만들기

사용 변수:  
'T_ID','VS_T_ID','TB_SC','AVG_cum','OBP_cum', 'SLG_cum', 'OPS_cum', 'ISO_cum', 'wOBA_cum', 'XR_cum', 'XR27_cum',
       'P_WHIP_RT', 'P2_WHIP_RT', 'CB_WHIP_RT', 'AWHIP', 'FIP', 'RA',
       'WLS_yest', 'rest_day', 'vs_conti'


```python
resid = pd.read_csv("잔여.csv")
resid.drop(['연번','요일'], axis=1, inplace=True)
resid.head()
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }
    
    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>일자</th>
      <th>AWAY</th>
      <th>HOME</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>9/29</td>
      <td>KIA</td>
      <td>키움</td>
    </tr>
    <tr>
      <th>1</th>
      <td>9/29</td>
      <td>KT</td>
      <td>삼성</td>
    </tr>
    <tr>
      <th>2</th>
      <td>9/29</td>
      <td>롯데</td>
      <td>LG</td>
    </tr>
    <tr>
      <th>3</th>
      <td>9/29</td>
      <td>두산</td>
      <td>한화</td>
    </tr>
    <tr>
      <th>4</th>
      <td>9/29</td>
      <td>SK</td>
      <td>NC</td>
    </tr>
  </tbody>
</table>
</div>




```python
resid['일자'] = resid['일자'].map(lambda x : x.replace('/', '-'))
resid['일자'] = pd.to_datetime(resid['일자'], format = '%m-%d')
```


```python
resid_1 = resid.copy()
```


```python
resid_1['T_ID'] = resid['HOME'] # resid_1이 home data, resid가 visit data라고 하자.
resid_1['VS_T_ID'] = resid['AWAY']

resid['T_ID'] = resid['AWAY']
resid['VS_T_ID'] = resid['HOME']
```


```python
resid_total = pd.concat([resid, resid_1]).sort_values(by = ['일자', 'T_ID', 'VS_T_ID', 'AWAY', 'HOME'])
resid_total = resid_total[['일자', 'T_ID', 'VS_T_ID', 'AWAY', 'HOME']]
```


```python
resid_total.sort_values(by=['일자', 'AWAY', 'HOME'], inplace = True)
resid_total.reset_index(inplace=True, drop=True)
```


```python
resid_total['TB_SC'] = resid_total.apply(lambda x : 0
                                        if(x['HOME'] == x['T_ID'])
                                        else 1, axis = 1)
```


```python
resid_total.drop(['AWAY', 'HOME'], axis=1, inplace=True)
resid_total
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }
    
    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>일자</th>
      <th>T_ID</th>
      <th>VS_T_ID</th>
      <th>TB_SC</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1900-09-29</td>
      <td>KIA</td>
      <td>키움</td>
      <td>1</td>
    </tr>
    <tr>
      <th>1</th>
      <td>1900-09-29</td>
      <td>키움</td>
      <td>KIA</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>1900-09-29</td>
      <td>KT</td>
      <td>삼성</td>
      <td>1</td>
    </tr>
    <tr>
      <th>3</th>
      <td>1900-09-29</td>
      <td>삼성</td>
      <td>KT</td>
      <td>0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>1900-09-29</td>
      <td>NC</td>
      <td>SK</td>
      <td>0</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>185</th>
      <td>1900-10-18</td>
      <td>키움</td>
      <td>두산</td>
      <td>0</td>
    </tr>
    <tr>
      <th>186</th>
      <td>1900-10-18</td>
      <td>NC</td>
      <td>롯데</td>
      <td>0</td>
    </tr>
    <tr>
      <th>187</th>
      <td>1900-10-18</td>
      <td>롯데</td>
      <td>NC</td>
      <td>1</td>
    </tr>
    <tr>
      <th>188</th>
      <td>1900-10-18</td>
      <td>삼성</td>
      <td>한화</td>
      <td>1</td>
    </tr>
    <tr>
      <th>189</th>
      <td>1900-10-18</td>
      <td>한화</td>
      <td>삼성</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
<p>190 rows × 4 columns</p>
</div>




```python
def change(x):
    if x == '두산' : 
        return 'OB'
    elif x == '키움':
        return 'WO'
    elif x == '삼성':
        return 'SS'
    elif x=='한화':
        return 'HH'
    elif x=='롯데':
        return 'LT'
    elif x=='KIA':
        return 'HT'
    else : 
        return x
```


```python
resid_total[['VS_T_ID', 'T_ID']] = resid_total[['VS_T_ID', 'T_ID']].applymap(lambda x: change(x))
resid_total
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }
    
    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>일자</th>
      <th>T_ID</th>
      <th>VS_T_ID</th>
      <th>TB_SC</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1900-09-29</td>
      <td>HT</td>
      <td>WO</td>
      <td>1</td>
    </tr>
    <tr>
      <th>1</th>
      <td>1900-09-29</td>
      <td>WO</td>
      <td>HT</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>1900-09-29</td>
      <td>KT</td>
      <td>SS</td>
      <td>1</td>
    </tr>
    <tr>
      <th>3</th>
      <td>1900-09-29</td>
      <td>SS</td>
      <td>KT</td>
      <td>0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>1900-09-29</td>
      <td>NC</td>
      <td>SK</td>
      <td>0</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>185</th>
      <td>1900-10-18</td>
      <td>WO</td>
      <td>OB</td>
      <td>0</td>
    </tr>
    <tr>
      <th>186</th>
      <td>1900-10-18</td>
      <td>NC</td>
      <td>LT</td>
      <td>0</td>
    </tr>
    <tr>
      <th>187</th>
      <td>1900-10-18</td>
      <td>LT</td>
      <td>NC</td>
      <td>1</td>
    </tr>
    <tr>
      <th>188</th>
      <td>1900-10-18</td>
      <td>SS</td>
      <td>HH</td>
      <td>1</td>
    </tr>
    <tr>
      <th>189</th>
      <td>1900-10-18</td>
      <td>HH</td>
      <td>SS</td>
      <td>0</td>
    </tr>
  </tbody>
</table>
<p>190 rows × 4 columns</p>
</div>




```python
team_list = resid_total['T_ID'].unique()
```

- 경기이전 휴식일수


```python
for i in team_list:
    globals()['resid_{}'.format(i)] = resid_total[resid_total['T_ID']==i].reset_index(drop = True)
```


```python
for i in team_list:
    globals()['resid_{}'.format(i)]['rest_day'] = 0
    for k in range(len(globals()['resid_{}'.format(i)])):
        if k==0:
            globals()['resid_{}'.format(i)]['rest_day'][k] = 2
        else: 
            globals()['resid_{}'.format(i)]['rest_day'][k] = globals()['resid_{}'.format(i)]['일자'][k] - globals()['resid_{}'.format(i)]['일자'][k-1]

    globals()['resid_{}'.format(i)]['rest_day'] = globals()['resid_{}'.format(i)]['rest_day'].astype(str) 
    p = re.compile('\d{1,3}')
    globals()['resid_{}'.format(i)]['rest_day'] = globals()['resid_{}'.format(i)]['rest_day'].map(lambda x: p.findall(x)[0])
    globals()['resid_{}'.format(i)]['rest_day'] = globals()['resid_{}'.format(i)]['rest_day'].astype(int) - 1
    globals()['resid_{}'.format(i)]['rest_day'] = globals()['resid_{}'.format(i)]['rest_day'].apply(lambda x: rest_day(x))
```

- 상대별 연전수


```python
#상대팀이 달라질 때마다 인덱스 초기화
for i in team_list:
    diffIndex=[0]
    for k in range(0, len(globals()['resid_{}'.format(i)])-1):
        if (globals()['resid_{}'.format(i)]['VS_T_ID'][k] != globals()['resid_{}'.format(i)]['VS_T_ID'][k+1]):
            diffIndex.append(k+1)
    
    globals()['resid_{}'.format(i)]['vs_conti'] = 0
    
    for q in range(len(diffIndex)-1) : 
        j = diffIndex[q+1]-diffIndex[q]
        globals()['resid_{}'.format(i)]['vs_conti'][diffIndex[q]:diffIndex[q+1]] = np.arange(0,j).tolist()

    j = len(globals()['resid_{}'.format(i)])- diffIndex[-1]
    globals()['resid_{}'.format(i)]['vs_conti'][diffIndex[-1]:] = np.arange(0,j).tolist()
```


```python
resid_total.sort_values(by = ['T_ID', '일자'], inplace= True)
```


```python
aa = pd.DataFrame(resid_LG)
```


```python
for i in team_list[1:]:
    aa = pd.concat([aa, globals()['resid_{}'.format(i)]])
```


```python
aa.sort_values(by=['T_ID', '일자'], inplace= True)
```


```python
aa.drop(['일자', 'T_ID', 'VS_T_ID', 'TB_SC'], axis = 1 , inplace= True)
```


```python
aa.reset_index(drop= True, inplace= True)
```


```python
resid_total.reset_index(drop = True, inplace= True)
```


```python
resid_total1 = pd.concat([resid_total, aa], axis =1)
resid_total1
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }
    
    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>일자</th>
      <th>T_ID</th>
      <th>VS_T_ID</th>
      <th>TB_SC</th>
      <th>rest_day</th>
      <th>vs_conti</th>
      <th>AVG_hat</th>
      <th>ERA_hat</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1900-09-29</td>
      <td>HH</td>
      <td>OB</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0.240974</td>
      <td>5.102540</td>
    </tr>
    <tr>
      <th>1</th>
      <td>1900-09-30</td>
      <td>HH</td>
      <td>OB</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0.241539</td>
      <td>5.116915</td>
    </tr>
    <tr>
      <th>2</th>
      <td>1900-10-01</td>
      <td>HH</td>
      <td>OB</td>
      <td>0</td>
      <td>0</td>
      <td>2</td>
      <td>0.247801</td>
      <td>5.284224</td>
    </tr>
    <tr>
      <th>3</th>
      <td>1900-10-02</td>
      <td>HH</td>
      <td>LT</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0.252753</td>
      <td>5.278717</td>
    </tr>
    <tr>
      <th>4</th>
      <td>1900-10-03</td>
      <td>HH</td>
      <td>LT</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0.249028</td>
      <td>5.084565</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>185</th>
      <td>1900-10-14</td>
      <td>WO</td>
      <td>KT</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0.264867</td>
      <td>4.642232</td>
    </tr>
    <tr>
      <th>186</th>
      <td>1900-10-15</td>
      <td>WO</td>
      <td>KT</td>
      <td>1</td>
      <td>0</td>
      <td>2</td>
      <td>0.267689</td>
      <td>4.467084</td>
    </tr>
    <tr>
      <th>187</th>
      <td>1900-10-16</td>
      <td>WO</td>
      <td>OB</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0.266542</td>
      <td>4.467916</td>
    </tr>
    <tr>
      <th>188</th>
      <td>1900-10-17</td>
      <td>WO</td>
      <td>OB</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0.265997</td>
      <td>4.468899</td>
    </tr>
    <tr>
      <th>189</th>
      <td>1900-10-18</td>
      <td>WO</td>
      <td>OB</td>
      <td>0</td>
      <td>0</td>
      <td>2</td>
      <td>0.266877</td>
      <td>4.554760</td>
    </tr>
  </tbody>
</table>
<p>190 rows × 8 columns</p>
</div>




```python
resid_total1.to_csv("승률_X_test.csv", encoding = 'cp949')
```

### 예측한 AVG/ERA 합치기


```python
test_ERA = pd.read_csv("ERA_X_test_예측값 (1).csv", encoding = 'cp949', index_col =0)
test_AVG = pd.read_csv("AVG_X_test_예측값.csv", encoding = 'cp949', index_col =0)
```


```python
test_AVG.columns = ['AVG_hat', 'T_ID1']
```


```python
test_EA = pd.concat([test_AVG, test_ERA], axis = 1)
test_EA.drop('T_ID1', axis =1, inplace = True)
```


```python
team_list
```




    array(['HT', 'WO', 'KT', 'SS', 'NC', 'SK', 'OB', 'HH', 'LG', 'LT'],
          dtype=object)




```python
for i in team_list:
    globals()['test_EA_{}'.format(i)] = test_EA[test_EA['T_ID'] == i].reset_index(drop= True)
    globals()['test_EA_{}'.format(i)].drop('T_ID', axis = 1, inplace = True)
```


```python
for i in team_list:
    globals()['resid_{}'.format(i)] = pd.concat([globals()['resid_{}'.format(i)], globals()['test_EA_{}'.format(i)]] , axis =1)
```

### 난수 생성


```python
total_data.reset_index(inplace= True, drop = True)
```


```python
diff = total_data['P2_WHIP_RT'][1:] - total_data['P2_WHIP_RT'].shift(1)[1:]
```


```python
P2_diff.describe()
```




    count    6333.000000
    mean       -0.000028
    std         1.306732
    min        -3.500000
    25%        -0.791667
    50%         0.000000
    75%         0.777778
    max         3.500000
    Name: P2_WHIP_RT, dtype: float64




```python
CBdiff = total_data['CB_WHIP_RT'][1:] - total_data['CB_WHIP_RT'].shift(1)[1:]
CBdiff.describe()
```




    count    6333.000000
    mean       -0.000041
    std         1.419669
    min        -4.000000
    25%        -0.900000
    50%         0.000000
    75%         0.900000
    max         4.125000
    Name: CB_WHIP_RT, dtype: float64




```python
Adiff = total_data['AWHIP'][1:] - total_data['AWHIP'].shift(1)[1:]
Adiff.describe()
```




    count    6333.000000
    mean       -0.000035
    std         0.790189
    min        -3.180556
    25%        -0.555556
    50%         0.000000
    75%         0.555556
    max         3.805556
    Name: AWHIP, dtype: float64



- P2_WHIP_RT : (-0.07, 0.07) 사이로 
- CB_WHIP_RT: (-0.09, 0.09) 사이로
- AWHIP : (-0.055, 0.055) 사이로 난수 생성


```python
P2_WHIP_rand = np.random.uniform(low = -0.07, high = 0.07, size = y_test.shape[0]) + total_data['P2_WHIP_RT'][-1267:]
CB_WHIP_rand = np.random.uniform(low = -0.09, high = 0.09, size = y_test.shape[0]) + total_data['CB_WHIP_RT'][-1267:]
AWHIP_rand = np.random.uniform(low = -0.055, high = 0.055, size = y_test.shape[0]) + total_data['AWHIP'][-1267:]
```


```python
P2_WHIP_rand.describe()
```




    count    1267.000000
    mean        1.521256
    std         0.841054
    min        -0.066217
    25%         0.962441
    50%         1.363316
    75%         1.974599
    max         3.568720
    Name: P2_WHIP_RT, dtype: float64




```python
total_data['P2_WHIP_RT'].describe()
```




    count    6334.000000
    mean        1.589621
    std         0.868912
    min         0.000000
    25%         1.000000
    50%         1.444444
    75%         2.000000
    max         3.500000
    Name: P2_WHIP_RT, dtype: float64




```python
CB_WHIP_rand.describe()
```




    count    1267.000000
    mean        1.679673
    std         0.953635
    min        -0.086632
    25%         1.001835
    50%         1.491061
    75%         2.177400
    max         4.214960
    Name: CB_WHIP_RT, dtype: float64




```python
total_data['CB_WHIP_RT'].describe()
```




    count    6334.000000
    mean        1.760556
    std         0.997848
    min         0.000000
    25%         1.000000
    50%         1.500000
    75%         2.250000
    max         4.125000
    Name: CB_WHIP_RT, dtype: float64




```python
AWHIP_rand.describe()
```




    count    1267.000000
    mean        1.430701
    std         0.528472
    min         0.193111
    25%         1.053089
    50%         1.385099
    75%         1.774579
    max         3.643177
    Name: AWHIP, dtype: float64




```python
total_data['AWHIP'].describe()
```




    count    6334.000000
    mean        1.504048
    std         0.547455
    min         0.111111
    25%         1.111111
    50%         1.444444
    75%         1.875000
    max         4.250000
    Name: AWHIP, dtype: float64



# 랜덤 넣은 모델링


```python
P2_WHIP_rand = np.random.uniform(low = -0.07, high = 0.07, size = total_data.shape[0]) + total_data['P2_WHIP_RT']
CB_WHIP_rand = np.random.uniform(low = -0.09, high = 0.09, size = total_data.shape[0]) + total_data['CB_WHIP_RT']
AWHIP_rand = np.random.uniform(low = -0.055, high = 0.055, size = total_data.shape[0]) + total_data['AWHIP']
```


```python
total_data[['P2_WHIP_RT', 'CB_WHIP_RT', 'AWHIP']][-190:]
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }
    
    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>P2_WHIP_RT</th>
      <th>CB_WHIP_RT</th>
      <th>AWHIP</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>6144</th>
      <td>0.931034</td>
      <td>1.090909</td>
      <td>1.100000</td>
    </tr>
    <tr>
      <th>6145</th>
      <td>1.500000</td>
      <td>1.250000</td>
      <td>1.500000</td>
    </tr>
    <tr>
      <th>6146</th>
      <td>0.333333</td>
      <td>0.333333</td>
      <td>0.333333</td>
    </tr>
    <tr>
      <th>6147</th>
      <td>1.250000</td>
      <td>1.500000</td>
      <td>1.250000</td>
    </tr>
    <tr>
      <th>6148</th>
      <td>1.125000</td>
      <td>0.545455</td>
      <td>1.111111</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>6329</th>
      <td>1.111111</td>
      <td>1.500000</td>
      <td>1.111111</td>
    </tr>
    <tr>
      <th>6330</th>
      <td>1.000000</td>
      <td>1.875000</td>
      <td>1.555556</td>
    </tr>
    <tr>
      <th>6331</th>
      <td>1.800000</td>
      <td>0.750000</td>
      <td>1.555556</td>
    </tr>
    <tr>
      <th>6332</th>
      <td>1.312500</td>
      <td>1.333333</td>
      <td>1.625000</td>
    </tr>
    <tr>
      <th>6333</th>
      <td>1.105263</td>
      <td>2.142857</td>
      <td>1.111111</td>
    </tr>
  </tbody>
</table>
<p>190 rows × 3 columns</p>
</div>




```python
total_data[['P2_WHIP_rand', 'CB_WHIP_rand', 'AWHIP_rand']][-190:]
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }
    
    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>P2_WHIP_rand</th>
      <th>CB_WHIP_rand</th>
      <th>AWHIP_rand</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>6144</th>
      <td>0.997135</td>
      <td>1.135397</td>
      <td>1.129027</td>
    </tr>
    <tr>
      <th>6145</th>
      <td>1.480732</td>
      <td>1.327054</td>
      <td>1.499269</td>
    </tr>
    <tr>
      <th>6146</th>
      <td>0.328761</td>
      <td>0.357739</td>
      <td>0.366984</td>
    </tr>
    <tr>
      <th>6147</th>
      <td>1.219122</td>
      <td>1.433396</td>
      <td>1.256605</td>
    </tr>
    <tr>
      <th>6148</th>
      <td>1.065512</td>
      <td>0.589122</td>
      <td>1.126842</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>6329</th>
      <td>1.132423</td>
      <td>1.576272</td>
      <td>1.134523</td>
    </tr>
    <tr>
      <th>6330</th>
      <td>0.933028</td>
      <td>1.860127</td>
      <td>1.580306</td>
    </tr>
    <tr>
      <th>6331</th>
      <td>1.816619</td>
      <td>0.747679</td>
      <td>1.601964</td>
    </tr>
    <tr>
      <th>6332</th>
      <td>1.333270</td>
      <td>1.245909</td>
      <td>1.580962</td>
    </tr>
    <tr>
      <th>6333</th>
      <td>1.065043</td>
      <td>2.171280</td>
      <td>1.128724</td>
    </tr>
  </tbody>
</table>
<p>190 rows × 3 columns</p>
</div>



### rand 1


```python
total_data['P2_WHIP_rand']  =  np.random.uniform(low = -0.07, high = 0.07, size = total_data.shape[0]) + total_data['P2_WHIP_RT']
total_data['CB_WHIP_rand'] = np.random.uniform(low = -0.09, high = 0.09, size = total_data.shape[0]) + total_data['CB_WHIP_RT']
total_data['AWHIP_rand']  = np.random.uniform(low = -0.055, high = 0.055, size = total_data.shape[0]) + total_data['AWHIP']

cols = ['T_ID','VS_T_ID','TB_SC','AVG','P2_WHIP_RT', 'CB_WHIP_RT', 'AWHIP','WLS_yest', 'rest_day', 'vs_conti', 'ERA', 'P2_WHIP_rand', 'CB_WHIP_rand', 'AWHIP_rand']

col_train = ['T_ID','VS_T_ID','TB_SC','AVG','P2_WHIP_RT', 'CB_WHIP_RT', 'AWHIP','WLS_yest', 'rest_day', 'vs_conti', 'ERA']
col_test = ['T_ID','VS_T_ID','TB_SC','AVG','P2_WHIP_rand', 'CB_WHIP_rand', 'AWHIP_rand', 'WLS_yest', 'rest_day', 'vs_conti', 'ERA']

X = total_data[cols]
y = total_data['WLS']
X_train, X_test, y_train,y_test = train_test_split(X, y, test_size=0.2, random_state=42)
X_train = X_train[col_train]
X_test = X_test[col_test]
X_test.columns = col_train

#col rand1
bag_clf = BaggingClassifier(DecisionTreeClassifier(), n_estimators=1600, max_samples=850, bootstrap=True, random_state=156)
bag_clf.fit(X_train, y_train)
bag_pred = bag_clf.predict(X_test)
pred_proba = bag_clf.predict_proba(X_test)[:, 1] #개별 레이블별 예측확률
get_clf_eval(y_test, bag_pred, pred_proba)
```

    오차 행렬
    [[552  84]
     [ 78 553]]
    정확도: 0.8721, 정밀도: 0.8681, 재현율: 0.8764, F1: 0.8722, AUC: 0.9474


### rand2


```python
total_data['P2_WHIP_rand2']  =  np.random.uniform(low = -0.07, high = 0.07, size = total_data.shape[0]) + total_data['P2_WHIP_RT']
total_data['CB_WHIP_rand2'] = np.random.uniform(low = -0.09, high = 0.09, size = total_data.shape[0]) + total_data['CB_WHIP_RT']
total_data['AWHIP_rand2']  = np.random.uniform(low = -0.055, high = 0.055, size = total_data.shape[0]) + total_data['AWHIP']

cols = ['T_ID','VS_T_ID','TB_SC','AVG','P2_WHIP_RT', 'CB_WHIP_RT', 'AWHIP','WLS_yest', 'rest_day', 'vs_conti', 'ERA', 'P2_WHIP_rand2', 'CB_WHIP_rand2', 'AWHIP_rand2']

col_train = ['T_ID','VS_T_ID','TB_SC','AVG','P2_WHIP_RT', 'CB_WHIP_RT', 'AWHIP','WLS_yest', 'rest_day', 'vs_conti', 'ERA']
col_test = ['T_ID','VS_T_ID','TB_SC','AVG','P2_WHIP_rand2', 'CB_WHIP_rand2', 'AWHIP_rand2', 'WLS_yest', 'rest_day', 'vs_conti', 'ERA']

X = total_data[cols]
y = total_data['WLS']
X_train, X_test, y_train,y_test = train_test_split(X, y, test_size=0.2, random_state=42)
X_train = X_train[col_train]
X_test = X_test[col_test]
X_test.columns = col_train


#col rand2
bag_clf = BaggingClassifier(DecisionTreeClassifier(), n_estimators=1600, max_samples=850, bootstrap=True, random_state=156)
bag_clf.fit(X_train, y_train)
bag_pred = bag_clf.predict(X_test)
pred_proba = bag_clf.predict_proba(X_test)[:, 1] #개별 레이블별 예측확률
get_clf_eval(y_test, bag_pred, pred_proba)
```

    오차 행렬
    [[553  83]
     [ 77 554]]
    정확도: 0.8737, 정밀도: 0.8697, 재현율: 0.8780, F1: 0.8738, AUC: 0.9473


### rand3


```python
total_data['P2_WHIP_rand3']  =  np.random.uniform(low = -0.07, high = 0.07, size = total_data.shape[0]) + total_data['P2_WHIP_RT']
total_data['CB_WHIP_rand3'] = np.random.uniform(low = -0.09, high = 0.09, size = total_data.shape[0]) + total_data['CB_WHIP_RT']
total_data['AWHIP_rand3']  = np.random.uniform(low = -0.055, high = 0.055, size = total_data.shape[0]) + total_data['AWHIP']

cols = ['T_ID','VS_T_ID','TB_SC','AVG','P2_WHIP_RT', 'CB_WHIP_RT', 'AWHIP','WLS_yest', 'rest_day', 'vs_conti', 'ERA', 'P2_WHIP_rand3', 'CB_WHIP_rand3', 'AWHIP_rand3']

col_train = ['T_ID','VS_T_ID','TB_SC','AVG','P2_WHIP_RT', 'CB_WHIP_RT', 'AWHIP','WLS_yest', 'rest_day', 'vs_conti', 'ERA']
col_test = ['T_ID','VS_T_ID','TB_SC','AVG','P2_WHIP_rand3', 'CB_WHIP_rand3', 'AWHIP_rand3', 'WLS_yest', 'rest_day', 'vs_conti', 'ERA']

X = total_data[cols]
y = total_data['WLS']
X_train, X_test, y_train,y_test = train_test_split(X, y, test_size=0.2, random_state=42)
X_train = X_train[col_train]
X_test = X_test[col_test]
X_test.columns = col_train

#col rand41
bag_clf = BaggingClassifier(DecisionTreeClassifier(), n_estimators=1600, max_samples=850, bootstrap=True, random_state=156)
bag_clf.fit(X_train, y_train)
bag_pred = bag_clf.predict(X_test)
pred_proba = bag_clf.predict_proba(X_test)[:, 1] #개별 레이블별 예측확률
get_clf_eval(y_test, bag_pred, pred_proba)
```

    오차 행렬
    [[557  79]
     [ 80 551]]
    정확도: 0.8745, 정밀도: 0.8746, 재현율: 0.8732, F1: 0.8739, AUC: 0.9479


### rand4


```python
total_data['P2_WHIP_rand4']  =  np.random.uniform(low = -0.07, high = 0.07, size = total_data.shape[0]) + total_data['P2_WHIP_RT']
total_data['CB_WHIP_rand4'] = np.random.uniform(low = -0.09, high = 0.09, size = total_data.shape[0]) + total_data['CB_WHIP_RT']
total_data['AWHIP_rand4']  = np.random.uniform(low = -0.055, high = 0.055, size = total_data.shape[0]) + total_data['AWHIP']

cols = ['T_ID','VS_T_ID','TB_SC','AVG','P2_WHIP_RT', 'CB_WHIP_RT', 'AWHIP','WLS_yest', 'rest_day', 'vs_conti', 'ERA', 'P2_WHIP_rand4', 'CB_WHIP_rand4', 'AWHIP_rand4']

col_train = ['T_ID','VS_T_ID','TB_SC','AVG','P2_WHIP_RT', 'CB_WHIP_RT', 'AWHIP','WLS_yest', 'rest_day', 'vs_conti', 'ERA']
col_test = ['T_ID','VS_T_ID','TB_SC','AVG','P2_WHIP_rand4', 'CB_WHIP_rand4', 'AWHIP_rand4', 'WLS_yest', 'rest_day', 'vs_conti', 'ERA']

X = total_data[cols]
y = total_data['WLS']
X_train, X_test, y_train,y_test = train_test_split(X, y, test_size=0.2, random_state=42)
X_train = X_train[col_train]
X_test = X_test[col_test]
X_test.columns = col_train

#col rand41
bag_clf = BaggingClassifier(DecisionTreeClassifier(), n_estimators=1600, max_samples=850, bootstrap=True, random_state=156)
bag_clf.fit(X_train, y_train)
bag_pred = bag_clf.predict(X_test)
pred_proba = bag_clf.predict_proba(X_test)[:, 1] #개별 레이블별 예측확률
get_clf_eval(y_test, bag_pred, pred_proba)
```

    오차 행렬
    [[549  87]
     [ 77 554]]
    정확도: 0.8706, 정밀도: 0.8643, 재현율: 0.8780, F1: 0.8711, AUC: 0.9481


### rand5


```python
total_data['P2_WHIP_rand5']  =  np.random.uniform(low = -0.07, high = 0.07, size = total_data.shape[0]) + total_data['P2_WHIP_RT']
total_data['CB_WHIP_rand5'] = np.random.uniform(low = -0.09, high = 0.09, size = total_data.shape[0]) + total_data['CB_WHIP_RT']
total_data['AWHIP_rand5']  = np.random.uniform(low = -0.055, high = 0.055, size = total_data.shape[0]) + total_data['AWHIP']

cols = ['T_ID','VS_T_ID','TB_SC','AVG','P2_WHIP_RT', 'CB_WHIP_RT', 'AWHIP','WLS_yest', 'rest_day', 'vs_conti', 'ERA', 'P2_WHIP_rand5', 'CB_WHIP_rand5', 'AWHIP_rand5']

col_train = ['T_ID','VS_T_ID','TB_SC','AVG','P2_WHIP_RT', 'CB_WHIP_RT', 'AWHIP','WLS_yest', 'rest_day', 'vs_conti', 'ERA']
col_test = ['T_ID','VS_T_ID','TB_SC','AVG','P2_WHIP_rand5', 'CB_WHIP_rand5', 'AWHIP_rand5', 'WLS_yest', 'rest_day', 'vs_conti', 'ERA']

X = total_data[cols]
y = total_data['WLS']
X_train, X_test, y_train,y_test = train_test_split(X, y, test_size=0.2, random_state=42)
X_train = X_train[col_train]
X_test = X_test[col_test]
X_test.columns = col_train

#col rand5
bag_clf = BaggingClassifier(DecisionTreeClassifier(), n_estimators=1600, max_samples=850, bootstrap=True, random_state=156)
bag_clf.fit(X_train, y_train)
bag_pred = bag_clf.predict(X_test)
pred_proba = bag_clf.predict_proba(X_test)[:, 1] #개별 레이블별 예측확률
get_clf_eval(y_test, bag_pred, pred_proba)
```

    오차 행렬
    [[551  85]
     [ 75 556]]
    정확도: 0.8737, 정밀도: 0.8674, 재현율: 0.8811, F1: 0.8742, AUC: 0.9474


### rand6


```python
total_data['P2_WHIP_rand6']  =  np.random.uniform(low = -0.07, high = 0.07, size = total_data.shape[0]) + total_data['P2_WHIP_RT']
total_data['CB_WHIP_rand6'] = np.random.uniform(low = -0.09, high = 0.09, size = total_data.shape[0]) + total_data['CB_WHIP_RT']
total_data['AWHIP_rand6']  = np.random.uniform(low = -0.055, high = 0.055, size = total_data.shape[0]) + total_data['AWHIP']

cols = ['T_ID','VS_T_ID','TB_SC','AVG','P2_WHIP_RT', 'CB_WHIP_RT', 'AWHIP','WLS_yest', 'rest_day', 'vs_conti', 'ERA', 'P2_WHIP_rand6', 'CB_WHIP_rand6', 'AWHIP_rand6']

col_train = ['T_ID','VS_T_ID','TB_SC','AVG','P2_WHIP_RT', 'CB_WHIP_RT', 'AWHIP','WLS_yest', 'rest_day', 'vs_conti', 'ERA']
col_test = ['T_ID','VS_T_ID','TB_SC','AVG','P2_WHIP_rand6', 'CB_WHIP_rand6', 'AWHIP_rand6', 'WLS_yest', 'rest_day', 'vs_conti', 'ERA']

X = total_data[cols]
y = total_data['WLS']
X_train, X_test, y_train,y_test = train_test_split(X, y, test_size=0.2, random_state=42)
X_train = X_train[col_train]
X_test = X_test[col_test]
X_test.columns = col_train

#col rand6
bag_clf = BaggingClassifier(DecisionTreeClassifier(), n_estimators=1600, max_samples=850, bootstrap=True, random_state=156)
bag_clf.fit(X_train, y_train)
bag_pred = bag_clf.predict(X_test)
pred_proba = bag_clf.predict_proba(X_test)[:, 1] #개별 레이블별 예측확률
get_clf_eval(y_test, bag_pred, pred_proba)
```

    오차 행렬
    [[554  82]
     [ 77 554]]
    정확도: 0.8745, 정밀도: 0.8711, 재현율: 0.8780, F1: 0.8745, AUC: 0.9469


### rand7


```python
total_data['P2_WHIP_rand7']  =  np.random.uniform(low = -0.07, high = 0.07, size = total_data.shape[0]) + total_data['P2_WHIP_RT']
total_data['CB_WHIP_rand7'] = np.random.uniform(low = -0.09, high = 0.09, size = total_data.shape[0]) + total_data['CB_WHIP_RT']
total_data['AWHIP_rand7']  = np.random.uniform(low = -0.055, high = 0.055, size = total_data.shape[0]) + total_data['AWHIP']

cols = ['T_ID','VS_T_ID','TB_SC','AVG','P2_WHIP_RT', 'CB_WHIP_RT', 'AWHIP','WLS_yest', 'rest_day', 'vs_conti', 'ERA', 'P2_WHIP_rand7', 'CB_WHIP_rand7', 'AWHIP_rand7']

col_train = ['T_ID','VS_T_ID','TB_SC','AVG','P2_WHIP_RT', 'CB_WHIP_RT', 'AWHIP','WLS_yest', 'rest_day', 'vs_conti', 'ERA']
col_test = ['T_ID','VS_T_ID','TB_SC','AVG','P2_WHIP_rand7', 'CB_WHIP_rand7', 'AWHIP_rand7', 'WLS_yest', 'rest_day', 'vs_conti', 'ERA']

X = total_data[cols]
y = total_data['WLS']
X_train, X_test, y_train,y_test = train_test_split(X, y, test_size=0.2, random_state=42)
X_train = X_train[col_train]
X_test = X_test[col_test]
X_test.columns = col_train

#col rand41
bag_clf = BaggingClassifier(DecisionTreeClassifier(), n_estimators=1600, max_samples=850, bootstrap=True, random_state=156)
bag_clf.fit(X_train, y_train)
bag_pred = bag_clf.predict(X_test)
pred_proba = bag_clf.predict_proba(X_test)[:, 1] #개별 레이블별 예측확률
get_clf_eval(y_test, bag_pred, pred_proba)
```

    오차 행렬
    [[555  81]
     [ 79 552]]
    정확도: 0.8737, 정밀도: 0.8720, 재현율: 0.8748, F1: 0.8734, AUC: 0.9477


### rand8


```python
total_data['P2_WHIP_rand8']  =  np.random.uniform(low = -0.07, high = 0.07, size = total_data.shape[0]) + total_data['P2_WHIP_RT']
total_data['CB_WHIP_rand8'] = np.random.uniform(low = -0.09, high = 0.09, size = total_data.shape[0]) + total_data['CB_WHIP_RT']
total_data['AWHIP_rand8']  = np.random.uniform(low = -0.055, high = 0.055, size = total_data.shape[0]) + total_data['AWHIP']

cols = ['T_ID','VS_T_ID','TB_SC','AVG','P2_WHIP_RT', 'CB_WHIP_RT', 'AWHIP','WLS_yest', 'rest_day', 'vs_conti', 'ERA', 'P2_WHIP_rand8', 'CB_WHIP_rand8', 'AWHIP_rand8']

col_train = ['T_ID','VS_T_ID','TB_SC','AVG','P2_WHIP_RT', 'CB_WHIP_RT', 'AWHIP','WLS_yest', 'rest_day', 'vs_conti', 'ERA']
col_test = ['T_ID','VS_T_ID','TB_SC','AVG','P2_WHIP_rand8', 'CB_WHIP_rand8', 'AWHIP_rand8', 'WLS_yest', 'rest_day', 'vs_conti', 'ERA']

X = total_data[cols]
y = total_data['WLS']
X_train, X_test, y_train,y_test = train_test_split(X, y, test_size=0.2, random_state=42)
X_train = X_train[col_train]
X_test = X_test[col_test]
X_test.columns = col_train

#col rand81
bag_clf = BaggingClassifier(DecisionTreeClassifier(), n_estimators=1600, max_samples=850, bootstrap=True, random_state=156)
bag_clf.fit(X_train, y_train)
bag_pred = bag_clf.predict(X_test)
pred_proba = bag_clf.predict_proba(X_test)[:, 1] #개별 레이블별 예측확률
get_clf_eval(y_test, bag_pred, pred_proba)
```

    오차 행렬
    [[553  83]
     [ 78 553]]
    정확도: 0.8729, 정밀도: 0.8695, 재현율: 0.8764, F1: 0.8729, AUC: 0.9470


### rand9


```python
total_data['P2_WHIP_rand9']  =  np.random.uniform(low = -0.07, high = 0.07, size = total_data.shape[0]) + total_data['P2_WHIP_RT']
total_data['CB_WHIP_rand9'] = np.random.uniform(low = -0.09, high = 0.09, size = total_data.shape[0]) + total_data['CB_WHIP_RT']
total_data['AWHIP_rand9']  = np.random.uniform(low = -0.055, high = 0.055, size = total_data.shape[0]) + total_data['AWHIP']

cols = ['T_ID','VS_T_ID','TB_SC','AVG','P2_WHIP_RT', 'CB_WHIP_RT', 'AWHIP','WLS_yest', 'rest_day', 'vs_conti', 'ERA', 'P2_WHIP_rand9', 'CB_WHIP_rand9', 'AWHIP_rand9']

col_train = ['T_ID','VS_T_ID','TB_SC','AVG','P2_WHIP_RT', 'CB_WHIP_RT', 'AWHIP','WLS_yest', 'rest_day', 'vs_conti', 'ERA']
col_test = ['T_ID','VS_T_ID','TB_SC','AVG','P2_WHIP_rand9', 'CB_WHIP_rand9', 'AWHIP_rand9', 'WLS_yest', 'rest_day', 'vs_conti', 'ERA']

X = total_data[cols]
y = total_data['WLS']
X_train, X_test, y_train,y_test = train_test_split(X, y, test_size=0.2, random_state=42)
X_train = X_train[col_train]
X_test = X_test[col_test]
X_test.columns = col_train

#col rand41
bag_clf = BaggingClassifier(DecisionTreeClassifier(), n_estimators=1600, max_samples=850, bootstrap=True, random_state=156)
bag_clf.fit(X_train, y_train)
bag_pred = bag_clf.predict(X_test)
pred_proba = bag_clf.predict_proba(X_test)[:, 1] #개별 레이블별 예측확률
get_clf_eval(y_test, bag_pred, pred_proba)
```

    오차 행렬
    [[554  82]
     [ 77 554]]
    정확도: 0.8745, 정밀도: 0.8711, 재현율: 0.8780, F1: 0.8745, AUC: 0.9469


### rand10


```python
total_data['P2_WHIP_rand10']  =  np.random.uniform(low = -0.07, high = 0.07, size = total_data.shape[0]) + total_data['P2_WHIP_RT']
total_data['CB_WHIP_rand10'] = np.random.uniform(low = -0.09, high = 0.09, size = total_data.shape[0]) + total_data['CB_WHIP_RT']
total_data['AWHIP_rand10']  = np.random.uniform(low = -0.055, high = 0.055, size = total_data.shape[0]) + total_data['AWHIP']

cols = ['T_ID','VS_T_ID','TB_SC','AVG','P2_WHIP_RT', 'CB_WHIP_RT', 'AWHIP', 'rest_day', 'vs_conti', 'ERA', 'P2_WHIP_rand10', 'CB_WHIP_rand10', 'AWHIP_rand10']

col_train = ['T_ID','VS_T_ID','TB_SC','AVG','P2_WHIP_RT', 'CB_WHIP_RT', 'AWHIP', 'rest_day', 'vs_conti', 'ERA']
col_test = ['T_ID','VS_T_ID','TB_SC','AVG','P2_WHIP_rand10', 'CB_WHIP_rand10', 'AWHIP_rand10',  'rest_day', 'vs_conti', 'ERA']

X = total_data[cols]
y = total_data['WLS']
X_train, X_test, y_train,y_test = train_test_split(X, y, test_size=0.2, random_state=42)
X_train = X_train[col_train]
X_test = X_test[col_test]
X_test.columns = col_train

#col rand41
bag_clf = BaggingClassifier(DecisionTreeClassifier(), n_estimators=1600, max_samples=850, bootstrap=True, random_state=156)
bag_clf.fit(X_train, y_train)
bag_pred = bag_clf.predict(X_test)
pred_proba = bag_clf.predict_proba(X_test)[:, 1] #개별 레이블별 예측확률
get_clf_eval(y_test, bag_pred, pred_proba)
```

    오차 행렬
    [[555  81]
     [ 79 552]]
    정확도: 0.8737, 정밀도: 0.8720, 재현율: 0.8748, F1: 0.8734, AUC: 0.9476


## F1 score를 봄 / 시뮬세이션 10개 평균 : 0.87336


```python
# 임계값
thresholds = [0.45, 0.46, 0.47, 0.48, 0.49, 0.50, 0.51, 0.52, 0.53, 0.54, 0.55]
pred_proba = bag_clf.predict_proba(X_test)
get_eval_by_threshold(y_test, pred_proba[:,1].reshape(-1, 1), thresholds)
```


    임계값:  0.45
    오차 행렬
    [[680 124]
     [ 75 705]]
    정확도: 0.8744, 정밀도: 0.8504, 재현율: 0.9038, F1: 0.8763, AUC: 0.9493
    
    임계값:  0.46
    오차 행렬
    [[686 118]
     [ 75 705]]
    정확도: 0.8782, 정밀도: 0.8566, 재현율: 0.9038, F1: 0.8796, AUC: 0.9493
    
    임계값:  0.47
    오차 행렬
    [[691 113]
     [ 78 702]]
    정확도: 0.8794, 정밀도: 0.8613, 재현율: 0.9000, F1: 0.8803, AUC: 0.9493
    
    임계값:  0.48
    오차 행렬
    [[693 111]
     [ 82 698]]
    정확도: 0.8782, 정밀도: 0.8628, 재현율: 0.8949, F1: 0.8785, AUC: 0.9493
    
    임계값:  0.49
    오차 행렬
    [[698 106]
     [ 87 693]]
    정확도: 0.8782, 정밀도: 0.8673, 재현율: 0.8885, F1: 0.8778, AUC: 0.9493
    
    임계값:  0.5
    오차 행렬
    [[701 103]
     [ 90 690]]
    정확도: 0.8782, 정밀도: 0.8701, 재현율: 0.8846, F1: 0.8773, AUC: 0.9493
    
    임계값:  0.51
    오차 행렬
    [[704 100]
     [ 92 688]]
    정확도: 0.8788, 정밀도: 0.8731, 재현율: 0.8821, F1: 0.8776, AUC: 0.9493
    
    임계값:  0.52
    오차 행렬
    [[706  98]
     [ 99 681]]
    정확도: 0.8756, 정밀도: 0.8742, 재현율: 0.8731, F1: 0.8736, AUC: 0.9493
    
    임계값:  0.53
    오차 행렬
    [[708  96]
     [102 678]]
    정확도: 0.8750, 정밀도: 0.8760, 재현율: 0.8692, F1: 0.8726, AUC: 0.9493
    
    임계값:  0.54
    오차 행렬
    [[716  88]
     [109 671]]
    정확도: 0.8756, 정밀도: 0.8841, 재현율: 0.8603, F1: 0.8720, AUC: 0.9493
    
    임계값:  0.55
    오차 행렬
    [[720  84]
     [114 666]]
    정확도: 0.8750, 정밀도: 0.8880, 재현율: 0.8538, F1: 0.8706, AUC: 0.9493



```python
# 임계값을 0.47로 설정하여 예측 수행
binarizer = Binarizer(threshold=0.47)

# 위에서 구한 predict_proba() 예측확률의 array에서 1에 해당하는 컬럼 값을 대입하여 Binarizer 반환하기
pred_th_047 = binarizer.fit_transform(pred_proba[:, 1].reshape(-1, 1))

get_clf_eval(y_test, pred_th_047, pred_proba[:,1])
```

    오차 행렬
    [[691 113]
     [ 78 702]]
    정확도: 0.8794, 정밀도: 0.8613, 재현율: 0.9000, F1: 0.8803, AUC: 0.9493



```python
bag_pred
```




    array([1, 0, 1, ..., 1, 1, 0], dtype=int64)



## 최종예측


```python
# label encoder
import numpy as np
from sklearn.preprocessing import LabelEncoder

# 라벨 인코더 생성
encoder = LabelEncoder()

# X_train데이터를 이용 피팅하고 라벨숫자로 변환한다
encoder.fit(resid_total1['T_ID'])
resid_total1['T_ID'] = encoder.transform(resid_total1['T_ID'])

encoder.fit(resid_total1['VS_T_ID'])
resid_total1['VS_T_ID'] = encoder.transform(resid_total1['VS_T_ID'])
```


```python
resid_total1.columns = ['일자','T_ID','VS_T_ID','TB_SC','rest_day', 'vs_conti', 'AVG','ERA', 'P2_WHIP_rand', 'CB_WHIP_rand', 'AWHIP_rand', 'WLS_yest']
```


```python
col_test = ['T_ID', 'VS_T_ID', 'TB_SC', 'rest_day', 'vs_conti', 'AVG','ERA', 'P2_WHIP_rand', 'CB_WHIP_rand', 'AWHIP_rand']
X_test_final = resid_total1[col_test]
bag_pred = bag_clf.predict(X_test_final)
pred_proba = bag_clf.predict_proba(X_test_final)[:, 1] #개별 레이블별 예측확률
```


```python
# 임계값을 0.49로 설정하여 예측 수행
binarizer = Binarizer(threshold=0.47)
# 위에서 구한 predict_proba() 예측확률의 array에서 1에 해당하는 컬럼 값을 대입하여 Binarizer 반환하기
pred_th_047 = binarizer.fit_transform(pred_proba.reshape(-1, 1))
```


```python
resid_total['final_pred_2'] = pred_th_047.flatten()
```


```python
resid_total['일자'] = resid_total['일자'].astype(str)
```


```python
resid_total['game_id'] = resid_total.apply(lambda x : x['일자'] + x['VS_T_ID'] + x['T_ID']
                                          if x['TB_SC'] == 0
                                          else x['일자'] + x['T_ID'] + x['VS_T_ID'], axis = 1)
```


```python
resid_total.drop('일자', axis=1, inplace=True)
```


```python
weight = pd.read_csv("가중치_데이터.csv", index_col=0) 
weight['combi'] = weight['team']+weight['vs_team']
```


```python
weight2 = weight.copy()
```


```python
weight2.drop(['wp_16', 'wp_17' ,'wp_18','wp_19', 'wp_20'], axis=1, inplace=True)
weight2
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }
    
    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>team</th>
      <th>vs_team</th>
      <th>combi</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>OB</td>
      <td>NC</td>
      <td>OBNC</td>
    </tr>
    <tr>
      <th>1</th>
      <td>OB</td>
      <td>WO</td>
      <td>OBWO</td>
    </tr>
    <tr>
      <th>2</th>
      <td>OB</td>
      <td>LG</td>
      <td>OBLG</td>
    </tr>
    <tr>
      <th>3</th>
      <td>OB</td>
      <td>HT</td>
      <td>OBHT</td>
    </tr>
    <tr>
      <th>4</th>
      <td>OB</td>
      <td>SK</td>
      <td>OBSK</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>85</th>
      <td>KT</td>
      <td>HT</td>
      <td>KTHT</td>
    </tr>
    <tr>
      <th>86</th>
      <td>KT</td>
      <td>SK</td>
      <td>KTSK</td>
    </tr>
    <tr>
      <th>87</th>
      <td>KT</td>
      <td>HH</td>
      <td>KTHH</td>
    </tr>
    <tr>
      <th>88</th>
      <td>KT</td>
      <td>LT</td>
      <td>KTLT</td>
    </tr>
    <tr>
      <th>89</th>
      <td>KT</td>
      <td>SS</td>
      <td>KTSS</td>
    </tr>
  </tbody>
</table>
<p>90 rows × 3 columns</p>
</div>




```python
# 현 승률 반영
def get_wp(x):
    if x=='OB':
        return  0.539
    elif x=='NC':
        return 0.628
    elif x=='SK':
        return 0.336
    elif x=='KT':
        return 0.336
    elif x=='LT':
        return 0.504
    elif x=='SS':
        return 0.448
    elif x=='HH':
        return 0.310
    elif x=='WO':
        return 0.577
    elif x=='HT':
        return 0.530
    elif x=='LG':
        return 0.560
```


```python
weight2['wp_20'] = weight2['team'].map(lambda x : get_wp(x))
weight2
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }
    
    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>team</th>
      <th>vs_team</th>
      <th>combi</th>
      <th>wp_20</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>OB</td>
      <td>NC</td>
      <td>OBNC</td>
      <td>0.539</td>
    </tr>
    <tr>
      <th>1</th>
      <td>OB</td>
      <td>WO</td>
      <td>OBWO</td>
      <td>0.539</td>
    </tr>
    <tr>
      <th>2</th>
      <td>OB</td>
      <td>LG</td>
      <td>OBLG</td>
      <td>0.539</td>
    </tr>
    <tr>
      <th>3</th>
      <td>OB</td>
      <td>HT</td>
      <td>OBHT</td>
      <td>0.539</td>
    </tr>
    <tr>
      <th>4</th>
      <td>OB</td>
      <td>SK</td>
      <td>OBSK</td>
      <td>0.539</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>85</th>
      <td>KT</td>
      <td>HT</td>
      <td>KTHT</td>
      <td>0.336</td>
    </tr>
    <tr>
      <th>86</th>
      <td>KT</td>
      <td>SK</td>
      <td>KTSK</td>
      <td>0.336</td>
    </tr>
    <tr>
      <th>87</th>
      <td>KT</td>
      <td>HH</td>
      <td>KTHH</td>
      <td>0.336</td>
    </tr>
    <tr>
      <th>88</th>
      <td>KT</td>
      <td>LT</td>
      <td>KTLT</td>
      <td>0.336</td>
    </tr>
    <tr>
      <th>89</th>
      <td>KT</td>
      <td>SS</td>
      <td>KTSS</td>
      <td>0.336</td>
    </tr>
  </tbody>
</table>
<p>90 rows × 4 columns</p>
</div>




```python
wp_merge = pd.merge(resid_total, weight, on = 'combi', how = 'left').sort_values(by = 'game_id')
```


```python
wp_merge['final_prob']= wp_merge.apply(lambda x : (x['final_pred_2']+1)*(x['wp_20']), axis = 1)
wp_merge.reset_index(inplace = True, drop = True)
```


```python
wp_merge['WL'] = 0
for i in range(0,len(wp_merge), 2) : 
    if wp_merge['final_prob'][i] > wp_merge['final_prob'][i+1] : 
        wp_merge['WL'][i] = 1; wp_merge['WL'][i+1] = 0
    else : 
        wp_merge['WL'][i] = 0; wp_merge['WL'][i+1] = 1
```


```python
wp_merge = pd.merge(resid_total, weight2, on = 'combi', how = 'left').sort_values(by = 'game_id')
wp_merge['final_prob']= wp_merge.apply(lambda x : (x['final_pred_2']+1)*(x['wp_20']), axis = 1)
wp_merge.reset_index(inplace = True, drop = True)
wp_merge['WL'] = 0
for i in range(0,len(wp_merge), 2) : 
    if wp_merge['final_prob'][i] > wp_merge['final_prob'][i+1] : 
        wp_merge['WL'][i] = 1; wp_merge['WL'][i+1] = 0
    else : 
        wp_merge['WL'][i] = 0; wp_merge['WL'][i+1] = 1
```


```python
final_4 = []
for team in team_list:
    win_count = len(wp_merge[(wp_merge['T_ID']==team)&(wp_merge['WL']==1)])
    total = len(wp_merge[wp_merge['T_ID']==team])
    wp = win_count/total
    final_4.append((team,wp))

final_4 = pd.DataFrame(final_4, columns=['T_ID', 'Win_prob'])
```


```python
final_4.to_csv("승률예측최종.csv")
```
